{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 패션 스타일별 소득 금액 예측 모델 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 이미지 데이터 변환 / json 파일에서 필요한 라벨 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# (1) json 파일에서 이미지에 대한 라벨을 추출하고 이미지 크기를 조절하는 전처리 함수 구현\n",
    "def read_img(folder_path):\n",
    "\n",
    "    file_list = os.listdir(folder_path)\n",
    "    feature_list = []\n",
    "    label_df = pd.DataFrame(columns=['era','style','age','job','income'])\n",
    "\n",
    "    for file in file_list:\n",
    "        # json 파일 로드, 필요한 정보 추출\n",
    "        with open(folder_path+file, 'r') as f: \n",
    "            data = json.load(f)\n",
    "        \n",
    "        # json 파일에서 파일명 읽어와 이미지 데이터 로드/300*400/0~1 정규화 => array 저장\n",
    "        img_path = folder_path.replace('label','img') + data['imgName']\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (300,400)) / 255.\n",
    "        \n",
    "        feature_list.append(img)\n",
    "\n",
    "        # 라벨 데이터 정수형으로 변경\n",
    "        k = [\"feminine\",\"classic\",\"minimal\",\"popart\",\"space\",\"hippie\",\"disco\",\n",
    "            \"military\",\"punk\",\"powersuit\",\"bodyconscious\",\"hiphop\",\"kitsch\",\n",
    "            \"lingerie\",\"grunge\",\"cityglam\",\"oriental\",\"ecology\",\"sportivecasual\",\n",
    "            \"athleisure\",\"lounge\",\"normcore\",\"genderless\"]\n",
    "        v = range(0,23)\n",
    "        style_dict = dict(zip(k, v))\n",
    "\n",
    "        # 라벨 df 생성\n",
    "        labels = [data['item']['era'], style_dict[data['item']['style']], data['user']['age'], data['user']['job'], data['user']['income']]\n",
    "        label_df.loc[label_df.shape[0]] = labels\n",
    "\n",
    "    # 최종 feature 데이터 생성\n",
    "    feature = np.array(feature_list)\n",
    "\n",
    "    return feature, label_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 로딩, 범주별 데이터 현황 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\n",
      "167\n",
      "174\n",
      "208\n",
      "145\n",
      "162\n",
      "201\n",
      "160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "income\n",
       "2    7113\n",
       "1    6744\n",
       "3    3332\n",
       "4    2039\n",
       "6    1828\n",
       "5    1440\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# style 컬럼 딕셔너리\n",
    "k = [\"feminine\",\"classic\",\"minimal\",\"popart\",\"space\",\"hippie\",\"disco\",\n",
    "    \"military\",\"punk\",\"powersuit\",\"bodyconscious\",\"hiphop\",\"kitsch\",\n",
    "    \"lingerie\",\"grunge\",\"cityglam\",\"oriental\",\"ecology\",\"sportivecasual\",\n",
    "    \"athleisure\",\"lounge\",\"normcore\",\"genderless\"]\n",
    "v = range(0,23)\n",
    "style_dict = dict(zip(k, v))\n",
    "\n",
    "\n",
    "# 타겟 데이터를 하나로 병합\n",
    "df = pd.DataFrame(columns=['era','style','age','job','income'])\n",
    "path = './data/target/'\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    one_df = pd.read_csv(path+file)\n",
    "    df = pd.concat([df, one_df], ignore_index=True)\n",
    "\n",
    "    # 각 파일별 최소 개수를 기준으로 데이터를 가져올 생각, 추출하여 확인\n",
    "    print(one_df['income'].value_counts()[5])\n",
    "\n",
    "# 최소 개수에 맞추어 다운샘플링하기 위한 개수 파악\n",
    "df['income'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 데이터 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 모델별 데이터를 1000개로 축소하여 npy/npz 파일로 변환하였음\n",
    "# npy 데이터\n",
    "feature_1990 = (np.load('./data/feature/1990.npy')*255).astype('uint8')\n",
    "feature_2000 = (np.load('./data/feature/2000.npy')*255).astype('uint8')\n",
    "feature_2019 = (np.load('./data/feature/2019.npy')*255).astype('uint8')\n",
    "\n",
    "# npz 데이터\n",
    "feature_1950 = (np.load('./data/feature/1950.npz')['images']*255).astype('uint8')\n",
    "feature_1960 = (np.load('./data/feature/1960.npz')['images']*255).astype('uint8')\n",
    "feature_1970 = (np.load('./data/feature/1970.npz')['images']*255).astype('uint8')\n",
    "feature_1980 = (np.load('./data/feature/1980.npz')['images']*255).astype('uint8')\n",
    "feature_2010 = (np.load('./data/feature/2010.npz')['images']*255).astype('uint8')\n",
    "\n",
    "# 피처 데이터를 하나로 병합\n",
    "feature = np.concatenate((feature_1950, feature_1960, feature_1970, feature_1980, feature_1990, feature_2000, feature_2010, feature_2019), axis=0)\n",
    "\n",
    "# 통합된 데이터 저장\n",
    "np.save('all.npy', feature)\n",
    "\n",
    "# float16 형식으로 데이터 로드\n",
    "feature_16 = np.load('./all.npy').astype('float16')\n",
    "\n",
    "feature_16 = feature_16 / 255.\n",
    "\n",
    "#  float16 형식으로 데이터 저장\n",
    "np.save('all_16.npy', feature_16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 피처 데이터 로딩\n",
    "feature = np.load('./all_16.npy')\n",
    "\n",
    "# 타겟 데이터를 하나로 병합\n",
    "df = pd.DataFrame(columns=['era','style','age','job','income'])\n",
    "path = './data/target/'\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    one_df = pd.read_csv(path+file)\n",
    "    df = pd.concat([df, one_df], ignore_index=True)\n",
    "\n",
    "# 라벨 원핫인코딩\n",
    "label = pd.get_dummies(df['income'], dtype=int)\n",
    "\n",
    "# 훈련/테스트용 데이터 분리\n",
    "train_X, test_X, train_y, test_y = train_test_split(feature, label, shuffle=True, stratify=label, random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout, Activation, BatchNormalization, ReLU\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "\n",
    "# 모델 구현\n",
    "model = Sequential()\n",
    "\n",
    "# 컨볼루션 레이어 추가\n",
    "model.add(Conv2D(32, kernel_size=(3,3), input_shape=(100,75,3)))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Activation(ReLU()))\n",
    "# model.add(MaxPooling2D())\n",
    "  \n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu'))     \n",
    "# model.add(BatchNormalization())\n",
    "model.add(Activation(ReLU()))                    \n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "# model.add(Conv2D(32, kernel_size=(3,3), activation='relu'))                         \n",
    "# # model.add(BatchNormalization())\n",
    "# model.add(Activation(ReLU()))                    \n",
    "# # model.add(MaxPooling2D())\n",
    "\n",
    "# model.add(Conv2D(32, kernel_size=(3,3), activation='relu'))     \n",
    "# # model.add(BatchNormalization())\n",
    "# model.add(Activation(ReLU()))                    \n",
    "# model.add(MaxPooling2D())\n",
    "\n",
    "# model.add(Dropout(0.25)) \n",
    "\n",
    "model.add(Flatten())                       \n",
    "\n",
    "model.add(Dense(32, kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(Dense(6, kernel_initializer='he_normal', activation='softmax'))\n",
    "\n",
    "# 에포크 별 최고 성능 모델 저장\n",
    "checkpoint = ModelCheckpoint('./best_model4.hdf5', monitor='val_loss', verbose=True, save_best_only=True)\n",
    "\n",
    "# 얼리스타핑\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=30)\n",
    "\n",
    "# # 러닝레이트\n",
    "# def scheduler(epoch, lr):\n",
    "#     if epoch > 20:\n",
    "#         return 0.000001\n",
    "#     else:\n",
    "#         return lr\n",
    "\n",
    "# learning_rate = LearningRateScheduler(scheduler)\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "\n",
    "model.fit(feature, label, epochs=1000, batch_size=32, validation_split=0.2, callbacks=[checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# 모델 로드\n",
    "model = load_model('./cnn_fashion_model_INCOME.hdf5')\n",
    "\n",
    "# 성능 평가\n",
    "model.predict(test_X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
